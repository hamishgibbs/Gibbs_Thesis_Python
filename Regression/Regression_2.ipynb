{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regression_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"l9cAg4213ezn","colab_type":"code","colab":{}},"source":["import geopandas\n","import pandas as pd\n","import numpy as np\n","from sklearn import linear_model\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn import model_selection\n","from sklearn import kernel_ridge\n","from sklearn import svm\n","from sklearn import tree\n","from sklearn import dummy\n","from sklearn import covariance\n","from sklearn import feature_selection\n","from sklearn import ensemble\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ji6MDW8i3j59","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":303},"outputId":"9af0309b-3aeb-4e93-8c80-f821f879120d","executionInfo":{"status":"ok","timestamp":1565075012421,"user_tz":-60,"elapsed":501,"user":{"displayName":"Hamish Gibbs","photoUrl":"","userId":"03305838575095682177"}}},"source":["fw_pts = geopandas.read_file('/Volumes/Gibbs_Drive/Data_Master/Points_S2_VI_S1_BP_S2RAT_S1RAT.shp')\n","points = fw_pts\n","X = points.loc[:, X_col_names]\n","print(' ')\n","points.plot()"],"execution_count":413,"outputs":[{"output_type":"stream","text":[" \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x1a225f5470>"]},"metadata":{"tags":[]},"execution_count":413},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"V41oNv4G3qXD","colab_type":"code","colab":{}},"source":["#Names of the independent variables that will be predicted:\n","y_col_names = ['Dry_wgh', 'Frsh_wg', 'FDN', 'FDA', 'CP', 'DIVMS']\n","y_col_full_names = ['Dry Weight Biomass', 'Fresh Weight Biomass', 'Neutral Detergent Fiber', 'Acid Detergent Fiber', 'Crude Protein', 'In-Vitro Dry Matter Digestibility']\n","\n","#Names of the predictor variables\n","X_col_names = list(points)[23:(len(list(points))-1)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1OPu_OdN4Ltl","colab_type":"code","colab":{}},"source":["def evaluate_model(reg, X_scaled, y_scaled):\n","  #previously used: neg_median_absolute_error, neg_mean_squared_error\n","  mse_scores = model_selection.cross_validate(reg, X_scaled, y_scaled, scoring='neg_median_absolute_error', cv=5)\n","  mse_scores = mse_scores['test_score']\n","  \n","  X_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=0)\n","  reg.fit(X_train, y_train)\n","  pred = reg.predict(X_test)\n","  r2 = metrics.r2_score(y_test, pred)\n","  return(mse_scores.mean(), r2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KO2tO7TH4-Be","colab_type":"code","colab":{}},"source":["#Give baseline prediction using MLR\n","mlr_data = []\n","\n","#Scale X data\n","X_scaled = points.loc[:, X_col_names]\n","\n","\n","for col in list(X_scaled):\n","  X_scaled.loc[:, col] = preprocessing.scale(np.array(X_scaled.loc[:, col]))\n","X_scaled = X_scaled.to_numpy()\n","\n","for var in y_col_names:\n","  y = np.array(points.loc[:, var])\n","  y_scaled = preprocessing.scale(y)\n","  y_scaled = np.ravel(y_scaled)\n","  y_scaled.shape\n","  \n","  reg = linear_model.LinearRegression()\n","  eval_result = evaluate_model(reg, X_scaled, y_scaled)\n","  mlr_data.append((var, type(reg).__name__, eval_result[0], eval_result[1]))\n","  \n","mlr_df = pd.DataFrame.from_dict(mlr_data, orient='columns', dtype=None, columns=None)\n","mlr_df.columns = ['variable', 'model_name', 'cv_mae', 'r2']\n","mlr_df.to_csv('/Volumes/Gibbs_Drive/Results/Non_Optimized_MLR_Performance.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXQ3b5Aq6yjL","colab_type":"code","colab":{}},"source":["regression_models = [linear_model.LinearRegression(), \n","                     linear_model.Ridge(alpha=.5),\n","                     linear_model.Lasso(alpha=0.1),\n","                     linear_model.BayesianRidge(),\n","                     kernel_ridge.KernelRidge(),\n","                     svm.LinearSVR(max_iter=5000),\n","                     tree.DecisionTreeRegressor(),\n","                     ensemble.RandomForestRegressor(n_estimators=10),\n","                     tree.ExtraTreeRegressor()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhTtEP-862yh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7d227ae9-728a-4ee1-82b3-31badc06b8dd","executionInfo":{"status":"ok","timestamp":1565075095935,"user_tz":-60,"elapsed":8500,"user":{"displayName":"Hamish Gibbs","photoUrl":"","userId":"03305838575095682177"}}},"source":["model_data = []\n","\n","#Scale X data\n","X_scaled = points.loc[:, X_col_names]\n","\n","\n","for col in list(X_scaled):\n","  X_scaled.loc[:, col] = preprocessing.scale(np.array(X_scaled.loc[:, col]))\n","X_scaled = X_scaled.to_numpy()\n","\n","#For each dependent variable, create new dataset, scale y data\n","for var in y_col_names:\n","  y = np.array(points.loc[:, var])\n","  y_scaled = preprocessing.scale(y)\n","  y_scaled = np.ravel(y_scaled)\n","  y_scaled.shape\n","  \n","  #for each regression model, test against the dependent variable\n","  for reg in regression_models:\n","    eval_result = evaluate_model(reg, X_scaled, y_scaled)\n","    model_data.append((var, type(reg).__name__, eval_result[0], eval_result[1]))\n"],"execution_count":420,"outputs":[{"output_type":"stream","text":["/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n","/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DU6teEK58Nc6","colab_type":"code","colab":{}},"source":["model_compare_df = pd.DataFrame.from_dict(model_data, orient='columns', dtype=None, columns=None)\n","model_compare_df.columns = ['variable', 'model_name', 'cv_mae', 'r2']\n","model_compare_df.to_csv('/Volumes/Gibbs_Drive/Results/Model_Comparison_2.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S2s2sJdf9dPz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"60b83f2f-3504-4da1-d760-48124dae01fa","executionInfo":{"status":"ok","timestamp":1565075097710,"user_tz":-60,"elapsed":83,"user":{"displayName":"Hamish Gibbs","photoUrl":"","userId":"03305838575095682177"}}},"source":["model_compare_df.head()"],"execution_count":422,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  variable        model_name     cv_mae        r2\n","0  Dry_wgh  LinearRegression -23.383864 -8.913612\n","1  Dry_wgh             Ridge  -0.926486  0.659163\n","2  Dry_wgh             Lasso  -0.822048  0.451008\n","3  Dry_wgh     BayesianRidge  -0.714324  0.592235\n","4  Dry_wgh       KernelRidge  -0.486827  0.669656"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>variable</th>\n","      <th>model_name</th>\n","      <th>cv_mae</th>\n","      <th>r2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dry_wgh</td>\n","      <td>LinearRegression</td>\n","      <td>-23.383864</td>\n","      <td>-8.913612</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dry_wgh</td>\n","      <td>Ridge</td>\n","      <td>-0.926486</td>\n","      <td>0.659163</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Dry_wgh</td>\n","      <td>Lasso</td>\n","      <td>-0.822048</td>\n","      <td>0.451008</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Dry_wgh</td>\n","      <td>BayesianRidge</td>\n","      <td>-0.714324</td>\n","      <td>0.592235</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dry_wgh</td>\n","      <td>KernelRidge</td>\n","      <td>-0.486827</td>\n","      <td>0.669656</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":422}]},{"cell_type":"code","metadata":{"id":"b5bzUeEJ63Kp","colab_type":"code","colab":{}},"source":["max_mse = pd.DataFrame([])\n","max_r2 = pd.DataFrame([])\n","\n","for var in y_col_names:\n","  max_mse = max_mse.append(model_compare_df.loc[model_compare_df.loc[model_compare_df['variable'] == var, :]['cv_mae'].idxmax(), :])\n","  \n","  max_r2 = max_r2.append(model_compare_df.loc[model_compare_df.loc[model_compare_df['variable'] == var, :]['r2'].idxmax(), :])\n","  \n","  #find the best model for each variable based on mse and r2 (may not be the same - favor mse)\n","max_mse.to_csv('/Volumes/Gibbs_Drive/Results/Non_Optimized_MAE_Performance.csv')\n","max_r2.to_csv('/Volumes/Gibbs_Drive/Results/Non_Optimized_R2_Performance.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pZ6bOJx_T-i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"e5683d63-a4f5-4cd7-d916-29d4fbb4f8e9","executionInfo":{"status":"ok","timestamp":1565075185280,"user_tz":-60,"elapsed":92,"user":{"displayName":"Hamish Gibbs","photoUrl":"","userId":"03305838575095682177"}}},"source":["max_mse"],"execution_count":425,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      cv_mae             model_name        r2 variable\n","4  -0.486827            KernelRidge  0.669656  Dry_wgh\n","13 -0.649007            KernelRidge  0.518494  Frsh_wg\n","25 -0.813400  RandomForestRegressor  0.561580      FDN\n","30 -0.716450          BayesianRidge  0.061550      FDA\n","40 -0.583779            KernelRidge  0.403573       CP\n","47 -0.668364                  Lasso  0.131021    DIVMS"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cv_mae</th>\n","      <th>model_name</th>\n","      <th>r2</th>\n","      <th>variable</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.486827</td>\n","      <td>KernelRidge</td>\n","      <td>0.669656</td>\n","      <td>Dry_wgh</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>-0.649007</td>\n","      <td>KernelRidge</td>\n","      <td>0.518494</td>\n","      <td>Frsh_wg</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>-0.813400</td>\n","      <td>RandomForestRegressor</td>\n","      <td>0.561580</td>\n","      <td>FDN</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>-0.716450</td>\n","      <td>BayesianRidge</td>\n","      <td>0.061550</td>\n","      <td>FDA</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>-0.583779</td>\n","      <td>KernelRidge</td>\n","      <td>0.403573</td>\n","      <td>CP</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>-0.668364</td>\n","      <td>Lasso</td>\n","      <td>0.131021</td>\n","      <td>DIVMS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":425}]},{"cell_type":"code","metadata":{"id":"_jhAOtxe_3Pc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"0309f1cd-3d43-4895-ddf1-2021f7f19859","executionInfo":{"status":"ok","timestamp":1565075185867,"user_tz":-60,"elapsed":80,"user":{"displayName":"Hamish Gibbs","photoUrl":"","userId":"03305838575095682177"}}},"source":["#Sample size is so small that it is affecting cross val, generalization error is overestimated (sklean docs)\n","#this is a tradeoff as random forest has some random performance\n","\n","max_r2"],"execution_count":426,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      cv_mae             model_name        r2 variable\n","4  -0.486827            KernelRidge  0.669656  Dry_wgh\n","13 -0.649007            KernelRidge  0.518494  Frsh_wg\n","25 -0.813400  RandomForestRegressor  0.561580      FDN\n","34 -0.751508  RandomForestRegressor  0.532126      FDA\n","43 -0.712716  RandomForestRegressor  0.706638       CP\n","52 -0.805849  RandomForestRegressor  0.475427    DIVMS"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cv_mae</th>\n","      <th>model_name</th>\n","      <th>r2</th>\n","      <th>variable</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.486827</td>\n","      <td>KernelRidge</td>\n","      <td>0.669656</td>\n","      <td>Dry_wgh</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>-0.649007</td>\n","      <td>KernelRidge</td>\n","      <td>0.518494</td>\n","      <td>Frsh_wg</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>-0.813400</td>\n","      <td>RandomForestRegressor</td>\n","      <td>0.561580</td>\n","      <td>FDN</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>-0.751508</td>\n","      <td>RandomForestRegressor</td>\n","      <td>0.532126</td>\n","      <td>FDA</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>-0.712716</td>\n","      <td>RandomForestRegressor</td>\n","      <td>0.706638</td>\n","      <td>CP</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>-0.805849</td>\n","      <td>RandomForestRegressor</td>\n","      <td>0.475427</td>\n","      <td>DIVMS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":426}]},{"cell_type":"code","metadata":{"id":"tf2rW_OsHny6","colab_type":"code","colab":{}},"source":["#using different approach to optimize feature set\n","#Rank independent variables by importance for each dependent variable (for RF)\n","feature_importance = []\n","\n","#Scale X data\n","X_scaled = points.loc[:, X_col_names]\n","\n","\n","for col in list(X_scaled):\n","  X_scaled.loc[:, col] = preprocessing.scale(np.array(X_scaled.loc[:, col]))\n","X_scaled = X_scaled.to_numpy()\n","\n","#For each dependent variable, create new dataset, scale y data\n","for var in y_col_names:\n","  y = np.array(points.loc[:, var])\n","  y_scaled = preprocessing.scale(y)\n","  y_scaled = np.ravel(y_scaled)\n","  y_scaled.shape\n","\n","  reg = ensemble.RandomForestRegressor(n_estimators=10)\n","  X_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=0)\n","  reg.fit(X_train, y_train)\n","  feature_importance = feature_importance + list(zip([var] * len(X_col_names), X_col_names, reg.feature_importances_))\n","\n","feature_importance_df = pd.DataFrame(feature_importance)\n","feature_importance_df.columns = ['variable', 'feature_name', 'importance']\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDgDwS7sTTsa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"962ced63-d58f-4e73-8498-22db8bff7ac2","executionInfo":{"status":"ok","timestamp":1565075223916,"user_tz":-60,"elapsed":77,"user":{"displayName":"Hamish Gibbs","photoUrl":"","userId":"03305838575095682177"}}},"source":["feature_importance_df.head()"],"execution_count":428,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  variable feature_name  importance\n","0  Dry_wgh           B2    0.000386\n","1  Dry_wgh           B3    0.000841\n","2  Dry_wgh           B4    0.000847\n","3  Dry_wgh           B5    0.001932\n","4  Dry_wgh           B6    0.002714"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>variable</th>\n","      <th>feature_name</th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dry_wgh</td>\n","      <td>B2</td>\n","      <td>0.000386</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dry_wgh</td>\n","      <td>B3</td>\n","      <td>0.000841</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Dry_wgh</td>\n","      <td>B4</td>\n","      <td>0.000847</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Dry_wgh</td>\n","      <td>B5</td>\n","      <td>0.001932</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dry_wgh</td>\n","      <td>B6</td>\n","      <td>0.002714</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":428}]},{"cell_type":"code","metadata":{"id":"pqFQ2bmaUWol","colab_type":"code","colab":{}},"source":["#only select features above mean importance of all features\n","\n","most_important = pd.DataFrame([])\n","\n","for var in y_col_names:\n","  \n","  group_mean = feature_importance_df.loc[feature_importance_df['variable'] == var, 'importance'].mean()\n","\n","  most_important = most_important.append(feature_importance_df.loc[(feature_importance_df['variable'] == var) & (feature_importance_df['importance'] >= group_mean), :].sort_values(by='importance', ascending=False))\n","most_important.to_csv('/Volumes/Gibbs_Drive/Results/Optimized_Variable_Names_RF.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibaiWll8V6ro","colab_type":"code","colab":{}},"source":["model_data_opt = []\n","\n","#repeat regression with different model but these selected variables\n","reg_var_pairs = [(kernel_ridge.KernelRidge(), 'Dry_wgh'),\n","                 (kernel_ridge.KernelRidge(), 'Frsh_wg'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'FDN'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'FDA'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'CP'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'DIVMS')]\n","\n","#check regression performance with optimized feature set here\n","\n","for pair in reg_var_pairs:\n","  reg = pair[0]\n","  var = pair[1]\n","  \n","  X_col_names_opt = list(most_important.loc[most_important['variable'] == var, 'feature_name'])\n","  \n","  X_scaled = points.loc[:, X_col_names_opt]\n","\n","  for col in list(X_scaled):\n","    X_scaled.loc[:, col] = preprocessing.scale(np.array(X_scaled.loc[:, col]))\n","  X_scaled = X_scaled.to_numpy()\n","\n","  y = np.array(points.loc[:, var])\n","  y_scaled = preprocessing.scale(y)\n","  y_scaled = np.ravel(y_scaled)\n","  y_scaled.shape\n","  \n","  eval_result = evaluate_model(reg, X_scaled, y_scaled)\n","  model_data_opt.append((var, type(reg).__name__, eval_result[0], eval_result[1]))\n","\n","#dataframe of regression performance using best performing r2 models from above and selected feature set from random forest feature selection (a different approach than previous)\n","model_compare_opt_df = pd.DataFrame.from_dict(model_data_opt, orient='columns', dtype=None, columns=None)\n","model_compare_opt_df.columns = ['variable', 'model_name', 'cv_mae', 'r2']\n","model_compare_opt_df.to_csv('/Volumes/Gibbs_Drive/Results/Optimized_Performance_RF.csv')\n","\n","#improved some model R2, didnt effect others"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2AZJXe9l65s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"4d56790e-7943-409a-9f9d-69d65dc49d34","executionInfo":{"status":"ok","timestamp":1565075711796,"user_tz":-60,"elapsed":339579,"user":{"displayName":"Hamish Gibbs","photoUrl":"","userId":"03305838575095682177"}}},"source":["#now, for each variable - make new y\n","#scale X\n","#for each number of possible variables, see which number produces best r2 result\n","\n","var_nums = []\n","variables =[]\n","prediction_results = []\n","\n","for var in y_col_names:\n","  print(var)\n","  y = np.array(points.loc[:, var])\n","  y = preprocessing.scale(y)\n","  y = np.ravel(y)\n","\n","  data_list = []\n","\n","  feature_nums = range(1, 129)\n","\n","  #Scale Data\n","  X_scaled = X\n","\n","  for col in list(X_scaled):\n","    X_scaled.loc[:, col] = preprocessing.scale(np.array(X_scaled.loc[:, col]))\n","  X_scaled = X_scaled.to_numpy()\n","  \n","  for num in feature_nums:\n","    X_new = feature_selection.SelectKBest(feature_selection.f_regression, k=num).fit_transform(X_scaled, y)\n","    X_scaled = X_new\n","  \n","    reg = ensemble.RandomForestRegressor(n_estimators=10)\n","    eval_result = evaluate_model(reg, X_scaled, y_scaled)\n","    r2 = eval_result[1]\n","     \n","    data_list.append((num, r2))\n","    \n","    X_scaled = X\n","    for col in list(X_scaled):\n","      X_scaled.loc[:, col] = preprocessing.scale(np.array(X_scaled.loc[:, col]))\n","    X_scaled = X_scaled.to_numpy()\n","    \n","  metric_df = pd.DataFrame.from_dict(data_list, orient='columns', dtype=None, columns=None)\n","  metric_df.columns = ['var_num', 'r2']\n","  \n","  #get index of maximum r2 value\n","  r2_max = metric_df['r2'].idxmax()\n","\n","  var_nums.append(r2_max)\n","  \n","  selector = feature_selection.SelectKBest(feature_selection.f_regression, k=(r2_max + 1))\n","  X_new = selector.fit_transform(X_scaled, y)\n","  X_scaled = X_new\n","  \n","  cols = selector.get_support(indices=True)\n","  X_col_new = X.iloc[:, cols]\n","  variables.append(list(X_col_new))\n","\n","  reg = ensemble.RandomForestRegressor(n_estimators=10)\n","  eval_result = evaluate_model(reg, X_scaled, y_scaled)\n","  mae = eval_result[0]\n","  r2 = eval_result[1]\n","  \n","  prediction_results.append((var, mae, r2))\n","#opt_prediction_df = pd.DataFrame.from_dict(prediction_results, orient='columns', dtype=None, columns=None)\n","#opt_prediction_df.columns = ['var_name', 'cv_mae', 'r2']\n","#opt_prediction_df.to_csv('/Volumes/Gibbs_Drive/Results/RF_Optimized_Prediction_Results.csv')\n","\n","variables_df = pd.DataFrame.from_records(variables)\n","variables_df = variables_df.transpose()\n","variables_df.columns = y_col_names\n","variables_df.to_csv('/Volumes/Gibbs_Drive/Results/Optimized_Variable_Names_KBest.csv')"],"execution_count":431,"outputs":[{"output_type":"stream","text":["Dry_wgh\n","Frsh_wg\n","FDN\n","FDA\n","CP\n","DIVMS\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sjHlYXNnh6xq","colab_type":"code","colab":{}},"source":["optimize_names = pd.read_csv('/Volumes/Gibbs_Drive/Results/Optimized_Variable_Names_KBest.csv').iloc[:, 1:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0RWQlXzhs00","colab_type":"code","colab":{}},"source":["model_data_opt_3 = []\n","\n","#repeat regression with different model but these selected variables\n","reg_var_pairs = [(kernel_ridge.KernelRidge(), 'Dry_wgh'),\n","                 (kernel_ridge.KernelRidge(), 'Frsh_wg'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'FDN'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'FDA'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'CP'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'DIVMS')]\n","\n","for pair in reg_var_pairs:\n","  reg = pair[0]\n","  var = pair[1]\n","  \n","  X_col_names_opt = list(optimize_names.loc[optimize_names[var].notna(), var])\n","  \n","  X_scaled = points.loc[:, X_col_names_opt]\n","  \n","  for col in list(X_scaled):\n","    X_scaled.loc[:, col] = preprocessing.scale(np.array(X_scaled.loc[:, col]))\n","  X_scaled = X_scaled.to_numpy()\n","\n","  y = np.array(points.loc[:, var])\n","  y_scaled = preprocessing.scale(y)\n","  y_scaled = np.ravel(y_scaled)\n","  y_scaled.shape\n","  \n","  eval_result = evaluate_model(reg, X_scaled, y_scaled)\n","  model_data_opt_3.append((var, type(reg).__name__, eval_result[0], eval_result[1]))\n","\n","#dataframe of regression performance using best performing r2 models from above and selected feature set from random forest feature selection (a different approach than previous)\n","model_compare_opt_3_df = pd.DataFrame.from_dict(model_data_opt_3, orient='columns', dtype=None, columns=None)\n","model_compare_opt_3_df.columns = ['variable', 'model_name', 'cv_mae', 'r2']\n","model_compare_opt_3_df.to_csv('/Volumes/Gibbs_Drive/Results/Optimized_Performance_KBest.csv')\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m0btD9sRTdgd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ec6TE9Tfpxdc","colab_type":"code","colab":{}},"source":["#pickle models for predictive modelling\n","\n","reg_var_pairs = [(kernel_ridge.KernelRidge(), 'Dry_wgh'),\n","                 (kernel_ridge.KernelRidge(), 'Frsh_wg'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'FDN'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'FDA'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'CP'),\n","                 (ensemble.RandomForestRegressor(n_estimators=10), 'DIVMS')]\n","\n","for pair in reg_var_pairs:\n","  reg = pair[0]\n","  var = pair[1]\n","  \n","\n","  X_col_names_opt = list(most_important.loc[most_important['variable'] == var, 'feature_name'])\n","  \n","  X_scaled = X.loc[:, X_col_names_opt]\n","  \n","  for col in list(X_scaled):\n","    X_scaled.loc[:, col] = preprocessing.scale(np.array(X_scaled.loc[:, col]))\n","  X_scaled = X_scaled.to_numpy()\n","\n","  y = np.array(points.loc[:, var])\n","  y = y.reshape(-1, 1)\n","  \n","  scalery = preprocessing.StandardScaler().fit(y)\n","  y_scaled = scalery.transform(y)\n","  y_scaled = y_scaled.reshape(-1)\n","  y_scaled = np.ravel(y_scaled)\n","  \n","  X_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaled, y, test_size=0.3, random_state=0)\n","  \n","  y_train = np.ravel(y_train)\n","  y_test = np.ravel(y_test)\n","  \n","  reg.fit(X_train, y_train)\n","  \n","  path = '/Volumes/Gibbs_Drive/Predictive_Modelling/Saved_Models/'\n","  fn = path + str(var) + '_model.p'\n","  pickle.dump(reg, open(fn, 'wb' ) )\n","\n","  s_fn = path + str(var) + '_scaler.p'\n","  pickle.dump(scalery, open(s_fn, 'wb' ) )\n","\n","#this is how to unscale the predictions:\n","#y_new_inverse = scalery.inverse_transform(pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oo-8RVu4yy11","colab_type":"code","colab":{}},"source":["#Check how many variables for each optimization\n","pred_var_nums = []\n","\n","kbest_names = pd.read_csv('/Volumes/Gibbs_Drive/Results/Optimized_Variable_Names_KBest.csv')\n","rf_names = pd.read_csv('/Volumes/Gibbs_Drive/Results/Optimized_Variable_Names_RF.csv')\n","\n","for var in y_col_names:\n","  kbest_num = len(kbest_names.loc[kbest_names[var].notna(), var])\n","  rf_num = len(rf_names.loc[rf_names['variable'] == var, 'feature_name'])\n","  \n","  pred_var_nums.append((var, kbest_num, rf_num))\n","\n","variable_numbers_df = pd.DataFrame.from_dict(pred_var_nums, orient='columns', dtype=None, columns=None)\n","variable_numbers_df.columns = ['variable', 'kbest_opt', 'rf_opt']\n","variable_numbers_df.to_csv('/Volumes/Gibbs_Drive/Results/Optimized_Var_Numbers.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccCEDjERgtHA","colab_type":"code","colab":{}},"source":["#new results section:\n","\n","#Why chose mae, not mse (robust to outliers) small sample size means large variance of cross val metrics\n","#relied more on R2 because \"generalizeability error can be overestimated for small datasets\"\n","\n","#1.\n","#performance of MLR for all variables (poor)\n","\n","#2.\n","#model comparison with different metrics - chose to favor R2 because of small sample size\n","#full data in appendix\n","\n","#3.\n","#two approaches to variable optimization:\n","#report regression ferformance with optimized feature sets\n","#report number of input features\n","#one with random forest, one with f-score select k best, see what effect of each\n","\n","#4.\n","#then,\n","#look at what variables are important (RF optimization gives a good idea, talk about S1 contribution, 8A important, somehow 11v12 important)\n","#talk about hwich veegtation indices, discuss how much each varibale contributed (sime much more than others)\n","#both of these data (names) in appendix\n","\n","#same with selectKbest optimization\n","#Discuss how this did not have all positive improvements for R2 what about mae?\n","#remember - with such a small training set, RF performance is very variable\n","\n","#rf feature selection looks better than kbest\n","\n","#now work on some graphs\n","#(divide point color by genotype?)\n","#make points not lines"],"execution_count":0,"outputs":[]}]}